{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento de um Modelo para Classificação de Tweets com Discursos de Ódio\n",
    "\n",
    "### Contém o código que rotula nosso dataset de avaliação, e verifica a acurácia para tweets customizados que criamos\n",
    "\n",
    "Membros: Lucas de Medeiros Soares, João Henrique Almeida Xavier e Tarso Jabbes Lima de Oliveira"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tarsojabbes/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criação do Pipeline com o Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"../model\"\n",
    "classifier = pipeline('text-classification', model= PATH, tokenizer= PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.read_csv('../Dados/test_data2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Assim, sim! Uma voz lúcida na cúpula da Igreja...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TODO ESQUERDISTA TEM UMA MENTE REDUCIONISTA ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Não se sinta mulher de verdade se você ofende ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bue fufas tão a seguir no insta pq wtf</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Não quer refugiados? Então pare de criá-los. h...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  label\n",
       "0  Assim, sim! Uma voz lúcida na cúpula da Igreja...      0\n",
       "1    TODO ESQUERDISTA TEM UMA MENTE REDUCIONISTA ...      1\n",
       "2  Não se sinta mulher de verdade se você ofende ...      1\n",
       "3             Bue fufas tão a seguir no insta pq wtf      1\n",
       "4  Não quer refugiados? Então pare de criá-los. h...      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_0', 'score': 0.9994864463806152}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(df_all['query'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execução do classificador para o dataset de avaliação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1074/1074 [01:12<00:00, 14.80it/s]\n"
     ]
    }
   ],
   "source": [
    "# Cria uma lista vazia para armazenar as previsões filtradas\n",
    "preds = []\n",
    "\n",
    "# Itera sobre as queries (texto) no DataFrame df_all\n",
    "# tqdm(df_all['query']): exibe uma barra de progresso enquanto itera sobre as queries\n",
    "for i, query in enumerate(tqdm(df_all['query'])):\n",
    "    try:\n",
    "        # Aplica o classificador ao texto (query) e obtém a previsão (pred)\n",
    "        pred = classifier(query)\n",
    "        \n",
    "        # Verifica se o rótulo previsto é 'LABEL_1' (discurso de ódio, por exemplo) e a confiança (score) é superior a 0.8\n",
    "        if pred[0]['label'] == 'LABEL_1' and pred[0]['score'] > 0.8:\n",
    "            # Se a condição for satisfeita, adiciona a query correspondente à lista 'preds'\n",
    "            preds.append(df_all['query'][i])\n",
    "    \n",
    "    # Tratamento de exceções: se ocorrer um erro de tempo de execução (RuntimeError), imprime a query que causou o erro\n",
    "    except RuntimeError as e:\n",
    "        print(f\"query: {query}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "424"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria uma nova coluna 'classification' no DataFrame df_all\n",
    "# A função lambda verifica se cada 'query' está na lista 'preds'\n",
    "# Se a query estiver na lista 'preds', atribui 1 (indica que foi classificada como LABEL_1, por exemplo)\n",
    "# Caso contrário, atribui 0 (indica que a query não foi classificada como LABEL_1)\n",
    "df_all['classification'] = df_all['query'].apply(lambda x: 1 if x in preds else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.to_csv('../Dados/results_data2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificação para exemplos extras criados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 21.04it/s]\n"
     ]
    }
   ],
   "source": [
    "# Carrega o DataFrame a partir de um arquivo CSV chamado 'custom.csv'\n",
    "df_custom = pd.read_csv('../Dados/custom.csv')\n",
    "\n",
    "# Inicializa uma lista vazia para armazenar as previsões filtradas\n",
    "preds = []\n",
    "\n",
    "# Itera sobre as queries no DataFrame df_custom, mostrando uma barra de progresso com tqdm\n",
    "for i, query in enumerate(tqdm(df_custom['query'])):\n",
    "    try:\n",
    "        # Aplica o classificador ao texto da query e obtém as previsões\n",
    "        pred = classifier(query)\n",
    "        \n",
    "        # Verifica se o rótulo da previsão é 'LABEL_1' (ex.: discurso de ódio) e a confiança é maior que 0.8\n",
    "        if pred[0]['label'] == 'LABEL_1' and pred[0]['score'] > 0.8:\n",
    "            # Adiciona a query à lista 'preds' se a condição for atendida\n",
    "            preds.append(df_custom['query'][i])    \n",
    "    except RuntimeError as e:\n",
    "        # Tratamento de exceção: imprime a query que gerou um erro de execução (se ocorrer)\n",
    "        print(f\"query: {query}\")\n",
    "\n",
    "# Adiciona uma nova coluna 'classification' ao DataFrame\n",
    "# Para cada query, a função lambda atribui 1 se ela estiver na lista 'preds', ou 0 se não estiver\n",
    "df_custom['classification'] = df_custom['query'].apply(lambda x: 1 if x in preds else 0)\n",
    "\n",
    "# Salva o DataFrame atualizado em um arquivo CSV chamado 'custom_result.csv' sem os índices\n",
    "df_custom.to_csv('../Dados/custom_result.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acertos: 19\n",
      "Erros: 1\n",
      "Porcentagem de Acertos: 95.00%\n"
     ]
    }
   ],
   "source": [
    "# Carrega o DataFrame contendo os resultados de classificação a partir do arquivo 'custom_result.csv'\n",
    "df_custom_result = pd.read_csv(\"../Dados/custom_result.csv\")\n",
    "\n",
    "# Cria uma nova coluna 'acerto' no DataFrame, que armazena True para acertos (quando 'label' e 'classification' são iguais)\n",
    "# e False para erros (quando 'label' e 'classification' são diferentes)\n",
    "df_custom_result['acerto'] = df_custom_result['label'] == df_custom_result['classification']\n",
    "\n",
    "# Conta o número de acertos somando os valores True na coluna 'acerto'\n",
    "acertos = df_custom_result['acerto'].sum()\n",
    "\n",
    "# Calcula o número de erros subtraindo o número de acertos do número total de exemplos no DataFrame\n",
    "erros = len(df_custom_result) - acertos\n",
    "\n",
    "# Exibe o número de acertos e erros\n",
    "print(f\"Acertos: {acertos}\")\n",
    "print(f\"Erros: {erros}\")\n",
    "\n",
    "# Calcula a porcentagem de acertos (acertos / número total de exemplos * 100)\n",
    "porcentagem_acertos = acertos / len(df_custom_result) * 100\n",
    "\n",
    "# Exibe a porcentagem de acertos formatada com 2 casas decimais\n",
    "print(f\"Porcentagem de Acertos: {porcentagem_acertos:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
